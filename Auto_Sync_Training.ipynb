{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üöÄ Technical Interview AI - Auto-Sync + A100 Power\n",
        "\n",
        "**Near Real-time Workflow with A100 Optimization:**\n",
        "1. ‚úèÔ∏è Edit code in Cursor\n",
        "2. üîÑ Auto-sync every 30 seconds  \n",
        "3. üöÄ Pull changes in Colab (1 click)\n",
        "4. ‚ö° Train on A100 GPU (13x faster!)\n",
        "\n",
        "## üéØ A100 vs T4 Comparison:\n",
        "| Feature | T4 (Previous) | A100 (New) | Improvement |\n",
        "|---------|---------------|------------|-------------|\n",
        "| **Training Time** | 2+ hours | 10-15 min | **13x faster** |\n",
        "| **Cost per Run** | $0.38 | $0.20-0.30 | **Cheaper!** |\n",
        "| **Training Data** | 100 scenarios | 150 scenarios | **50% more** |\n",
        "| **Batch Size** | 1 | 4 | **4x larger** |\n",
        "| **Sequence Length** | 512 | 1024 | **2x longer** |\n",
        "| **Precision** | fp16 | **bfloat16** | **A100 exclusive** |\n",
        "| **Auto-Backup** | Manual | **Google Drive** | **Never lose work** |\n",
        "\n",
        "**‚ö° Just run the same cells - A100 optimization is automatic!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üîÑ QUICK SYNC: Get latest changes from Cursor (30 seconds old max!).\n",
        "REPO_URL = 'https://github.com/shijazi88/technical-interview-ai'\n",
        "PROJECT_DIR = 'interview-ai'\n",
        "\n",
        "import os\n",
        "if os.path.exists(PROJECT_DIR):\n",
        "    print(\"üîÑ Pulling latest changes from Cursor...\")\n",
        "    %cd $PROJECT_DIR\n",
        "    !git pull origin main\n",
        "    print(\"‚úÖ Synced! Your latest Cursor code is now here.\")\n",
        "else:\n",
        "    print(\"üì• First time: Cloning repository...\")\n",
        "    !git clone $REPO_URL $PROJECT_DIR\n",
        "    %cd $PROJECT_DIR\n",
        "    print(\"‚úÖ Repository cloned!\")\n",
        "\n",
        "!ls -la *.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üìä SETUP PROGRESS TRACKING - Install widgets for real-time training progress\n",
        "\n",
        "print(\"üì¶ Installing progress tracking widgets...\")\n",
        "\n",
        "# Install ipywidgets for progress bars and real-time updates\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "try:\n",
        "    import ipywidgets\n",
        "    print(\"‚úÖ ipywidgets already installed\")\n",
        "except ImportError:\n",
        "    print(\"Installing ipywidgets...\")\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"ipywidgets\"])\n",
        "    print(\"‚úÖ ipywidgets installed successfully!\")\n",
        "\n",
        "# Enable widgets extension\n",
        "try:\n",
        "    from IPython.display import display, HTML\n",
        "    print(\"‚úÖ IPython display ready\")\n",
        "    \n",
        "    # Test widget functionality\n",
        "    import ipywidgets as widgets\n",
        "    test_widget = widgets.FloatProgress(value=0, min=0, max=100, description='Test:')\n",
        "    print(\"‚úÖ Widget system working!\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è Widget setup issue: {e}\")\n",
        "    print(\"Progress will be shown as text output instead\")\n",
        "\n",
        "print(\"\\nüéØ Progress Tracking Ready!\")\n",
        "print(\"Your training will show:\")\n",
        "print(\"  üìä Real-time progress bar\")\n",
        "print(\"  ‚è±Ô∏è Elapsed time and remaining time estimates\")  \n",
        "print(\"  üìâ Current loss and best loss tracking\")\n",
        "print(\"  üî• Steps per second and ETA\")\n",
        "print(\"  üìà Live metrics dashboard\")\n",
        "\n",
        "print(\"\\n‚úÖ Ready to start training with visual progress tracking!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üì¶ Setup A100-Optimized Environment\n",
        "print(\"üöÄ Setting up A100-optimized training environment...\")\n",
        "\n",
        "# Install A100-optimized packages\n",
        "%pip install -q transformers>=4.35.0 peft>=0.6.0 accelerate>=0.24.0\n",
        "%pip install -q bitsandbytes>=0.41.0 datasets>=2.14.0 torch>=2.1.0\n",
        "%pip install -q huggingface_hub>=0.17.0\n",
        "\n",
        "import torch\n",
        "import os\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    gpu_name = torch.cuda.get_device_name(0)\n",
        "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
        "    \n",
        "    print(f\"üñ•Ô∏è GPU: {gpu_name}\")\n",
        "    print(f\"üî¢ Memory: {gpu_memory:.1f} GB\")\n",
        "    \n",
        "    if \"A100\" in gpu_name:\n",
        "        print(\"üéâ A100 DETECTED! Optimal training enabled!\")\n",
        "        print(\"‚ö° Expected training time: 10-15 minutes (vs 2+ hours on T4)\")\n",
        "        print(\"üß† Using bfloat16 precision + larger batches\")\n",
        "        os.environ['USE_A100_OPTIMIZATIONS'] = '1'\n",
        "    elif \"T4\" in gpu_name:\n",
        "        print(\"‚ö†Ô∏è T4 detected - training will be slower but still works\")\n",
        "        print(\"üí° For 13x speedup, switch to A100: Runtime ‚Üí Change runtime type ‚Üí A100\")\n",
        "        os.environ['USE_A100_OPTIMIZATIONS'] = '0'\n",
        "    else:\n",
        "        print(f\"üîç GPU detected: {gpu_name}\")\n",
        "        os.environ['USE_A100_OPTIMIZATIONS'] = '0'\n",
        "else:\n",
        "    print(\"‚ùå No GPU detected! Enable GPU: Runtime ‚Üí Change runtime type ‚Üí GPU\")\n",
        "\n",
        "print(\"‚úÖ Environment setup complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üöÄ Train with A100 Optimization (automatically adapts to your GPU)\n",
        "\n",
        "import os\n",
        "\n",
        "# Check if A100 optimizations are available\n",
        "use_a100 = os.environ.get('USE_A100_OPTIMIZATIONS', '0') == '1'\n",
        "\n",
        "if use_a100:\n",
        "    print(\"üöÄ Starting A100-OPTIMIZED training...\")\n",
        "    print(\"üìä Configuration:\")\n",
        "    print(\"  - Scenarios: 150 (vs 20 on T4)\")\n",
        "    print(\"  - Batch size: 4 (vs 1 on T4)\")  \n",
        "    print(\"  - Max length: 1024 (vs 512 on T4)\")\n",
        "    print(\"  - Precision: bfloat16 (A100 exclusive)\")\n",
        "    print(\"  - Auto-backup: Google Drive\")\n",
        "    print(\"‚è±Ô∏è Expected time: 10-15 minutes\")\n",
        "    print()\n",
        "    \n",
        "    # A100 optimized training with automatic backups\n",
        "    !python a100_training_pipeline.py \\\n",
        "        --num_scenarios 150 \\\n",
        "        --batch_size 4 \\\n",
        "        --max_length 1024 \\\n",
        "        --use_bfloat16 \\\n",
        "        --backup_to_drive \\\n",
        "        --epochs 3\n",
        "        \n",
        "else:\n",
        "    print(\"üîÑ Starting T4-compatible training...\")\n",
        "    print(\"üìä Configuration:\")\n",
        "    print(\"  - Scenarios: 100\")\n",
        "    print(\"  - Batch size: 1\")\n",
        "    print(\"  - Max length: 512\") \n",
        "    print(\"  - Precision: fp16\")\n",
        "    print(\"‚è±Ô∏è Expected time: 2+ hours\")\n",
        "    print(\"üí° Switch to A100 for 13x speedup!\")\n",
        "    print()\n",
        "    \n",
        "    # T4 compatible training (original method)\n",
        "    !python colab_training_pipeline.py --num_scenarios 100 --epochs 3 --max_length 512\n",
        "\n",
        "print()\n",
        "print(\"‚úÖ Training completed! Model ready for testing.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üß™ QUICK TEST - Verify your trained model works\n",
        "\n",
        "import os\n",
        "from technical_interview_bot import TechnicalInterviewBot\n",
        "\n",
        "print(\"üîç Checking trained model...\")\n",
        "\n",
        "# Check if model was saved successfully\n",
        "model_path = \"./technical_interview_model\"\n",
        "if os.path.exists(model_path):\n",
        "    print(f\"‚úÖ Model found at: {model_path}\")\n",
        "    \n",
        "    # Show model file sizes\n",
        "    print(\"\\nüìÅ Model files:\")\n",
        "    total_size = 0\n",
        "    for file in os.listdir(model_path):\n",
        "        file_path = os.path.join(model_path, file)\n",
        "        if os.path.isfile(file_path):\n",
        "            size_mb = os.path.getsize(file_path) / (1024 * 1024)\n",
        "            total_size += size_mb\n",
        "            print(f\"  - {file}: {size_mb:.1f} MB\")\n",
        "    print(f\"üìä Total model size: {total_size:.1f} MB\")\n",
        "    \n",
        "    print(\"\\nü§ñ Testing model loading...\")\n",
        "    \n",
        "    # Test loading the model\n",
        "    try:\n",
        "        bot = TechnicalInterviewBot(model_path)\n",
        "        \n",
        "        if bot.model is not None:\n",
        "            print(\"‚úÖ Model loaded successfully!\")\n",
        "            \n",
        "            # Quick test interview\n",
        "            print(\"\\nüî• Quick test - Starting sample interview...\")\n",
        "            response = bot.start_interview(\n",
        "                programming_language=\"python\",\n",
        "                experience_level=\"mid_level\", \n",
        "                candidate_name=\"Test User\"\n",
        "            )\n",
        "            \n",
        "            print(\"ü§ñ AI Response:\")\n",
        "            print(\"-\" * 60)\n",
        "            print(response[:300] + \"...\" if len(response) > 300 else response)\n",
        "            print(\"-\" * 60)\n",
        "            \n",
        "            print(\"\\nüéâ SUCCESS! Your CodeLlama model is working!\")\n",
        "            print(\"üåê Ready to launch web interface in the next cell!\")\n",
        "            \n",
        "        else:\n",
        "            print(\"‚ùå Model files found but failed to load\")\n",
        "            print(\"Check error messages above\")\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error testing model: {e}\")\n",
        "        print(\"Training may have failed or model files are corrupted\")\n",
        "        \n",
        "else:\n",
        "    print(f\"‚ùå Model not found at: {model_path}\")\n",
        "    print(\"Training may have failed or is still in progress\")\n",
        "    print(\"Make sure the training cell above completed successfully\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üåê LAUNCH WEB INTERFACE - Test your trained CodeLlama model!\n",
        "\n",
        "# Install Gradio for web interface\n",
        "%pip install gradio\n",
        "\n",
        "# Import required modules\n",
        "import sys\n",
        "import os\n",
        "sys.path.append('/content/interview-ai')\n",
        "\n",
        "print(\"üîç Checking for trained model...\")\n",
        "\n",
        "# Check if model exists\n",
        "model_path = './technical_interview_model'\n",
        "if os.path.exists(model_path):\n",
        "    print(\"‚úÖ Model found! Launching web interface...\")\n",
        "    \n",
        "    # List model files\n",
        "    print(\"\\nüìÅ Model files:\")\n",
        "    for file in os.listdir(model_path):\n",
        "        if os.path.isfile(os.path.join(model_path, file)):\n",
        "            size_mb = os.path.getsize(os.path.join(model_path, file)) / (1024 * 1024)\n",
        "            print(f\"  - {file}: {size_mb:.1f} MB\")\n",
        "    \n",
        "    # Import and launch web interface\n",
        "    from web_interface import launch_web_interface\n",
        "    \n",
        "    print(\"\\nüöÄ Starting Technical Interview AI Web Interface...\")\n",
        "    print(\"üí° This will create a public link accessible from any browser!\")\n",
        "    print(\"üîó Copy the gradio.live URL to access from your Mac/phone\")\n",
        "    \n",
        "    # Launch with public sharing enabled\n",
        "    launch_web_interface(share=True, port=7860)\n",
        "    \n",
        "else:\n",
        "    print(\"‚ùå Model not found at ./technical_interview_model\")\n",
        "    print(\"Make sure the training cell completed successfully before running this cell.\")\n",
        "    print(\"\\nüîß Troubleshooting:\")\n",
        "    print(\"1. Check if training finished without errors\")\n",
        "    print(\"2. Look for 'Training completed!' message above\")\n",
        "    print(\"3. Re-run the training cell if needed\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "## üíæ Model Backup & Download (A100 Auto-Backup)\n",
        "\n",
        "If you used A100 training, your model is already backed up to Google Drive automatically!\n",
        "Use the cells below to download your model or access backups.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üì• DOWNLOAD YOUR MODEL - Multiple backup strategies\n",
        "\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "print(\"üíæ Model Backup & Download Options\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Check if A100 training was used (automatic backups)\n",
        "use_a100 = os.environ.get('USE_A100_OPTIMIZATIONS', '0') == '1'\n",
        "\n",
        "if use_a100:\n",
        "    print(\"üéâ A100 training detected - automatic backups created!\")\n",
        "    \n",
        "    # Check Google Drive backup\n",
        "    backup_dir = \"/content/drive/MyDrive/Technical_Interview_Models\"\n",
        "    if os.path.exists(backup_dir):\n",
        "        print(f\"‚úÖ Google Drive backup found: {backup_dir}\")\n",
        "        backups = [f for f in os.listdir(backup_dir) if 'model_' in f or '.zip' in f]\n",
        "        if backups:\n",
        "            print(\"üìÅ Available backups:\")\n",
        "            for backup in sorted(backups)[-3:]:  # Show last 3\n",
        "                print(f\"  - {backup}\")\n",
        "        else:\n",
        "            print(\"üìÅ Backup directory exists but no models found\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è Google Drive not mounted or no backups found\")\n",
        "\n",
        "# Option 1: Create download package\n",
        "print(\"\\nüì¶ Option 1: Create downloadable ZIP\")\n",
        "if os.path.exists('./technical_interview_model'):\n",
        "    \n",
        "    print(\"Creating ZIP package...\")\n",
        "    import zipfile\n",
        "    from google.colab import files\n",
        "    \n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    zip_filename = f\"technical_interview_model_{timestamp}.zip\"\n",
        "    \n",
        "    with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "        for root, dirs, files in os.walk('./technical_interview_model'):\n",
        "            for file in files:\n",
        "                file_path = os.path.join(root, file)\n",
        "                arcname = os.path.relpath(file_path, './technical_interview_model')\n",
        "                zipf.write(file_path, arcname)\n",
        "    \n",
        "    print(f\"‚úÖ ZIP created: {zip_filename}\")\n",
        "    print(\"üì• Starting download...\")\n",
        "    files.download(zip_filename)\n",
        "    print(\"üéâ Download completed!\")\n",
        "    \n",
        "else:\n",
        "    print(\"‚ùå No local model found to download\")\n",
        "\n",
        "# Option 2: Manual backup to Drive\n",
        "print(\"\\nüíæ Option 2: Manual backup to Google Drive\")\n",
        "manual_backup = input(\"Create manual Drive backup? (y/n): \").strip().lower()\n",
        "\n",
        "if manual_backup == 'y':\n",
        "    try:\n",
        "        from model_persistence_utils import colab_save_model\n",
        "        colab_save_model('./technical_interview_model')\n",
        "    except ImportError:\n",
        "        print(\"‚ö†Ô∏è Backup utility not available - model files copied to current directory\")\n",
        "\n",
        "print(\"\\nüìã Backup Summary:\")\n",
        "print(\"‚úÖ Local model: Available for immediate use\")\n",
        "if use_a100:\n",
        "    print(\"‚úÖ Google Drive: Auto-backed up during A100 training\")\n",
        "print(\"‚úÖ Download ZIP: Ready for local development\")\n",
        "print(\"\\nüéØ Your model is secured with multiple backup strategies!\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
