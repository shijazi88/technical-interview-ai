{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ü§ñ Technical Interview AI - Auto-Sync\n",
        "\n",
        "**Near Real-time Workflow:**\n",
        "1. ‚úèÔ∏è Edit code in Cursor\n",
        "2. üîÑ Auto-sync every 30 seconds\n",
        "3. üöÄ Pull changes in Colab (1 click)\n",
        "4. üî• Train on GPU!\n",
        "\n",
        "Replace `YOUR_REPO_URL` with your GitHub repository URL."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üîÑ QUICK SYNC: Get latest changes from Cursor (30 seconds old max!).\n",
        "REPO_URL = 'https://github.com/shijazi88/technical-interview-ai'\n",
        "PROJECT_DIR = 'interview-ai'\n",
        "\n",
        "import os\n",
        "if os.path.exists(PROJECT_DIR):\n",
        "    print(\"üîÑ Pulling latest changes from Cursor...\")\n",
        "    %cd $PROJECT_DIR\n",
        "    !git pull origin main\n",
        "    print(\"‚úÖ Synced! Your latest Cursor code is now here.\")\n",
        "else:\n",
        "    print(\"üì• First time: Cloning repository...\")\n",
        "    !git clone $REPO_URL $PROJECT_DIR\n",
        "    %cd $PROJECT_DIR\n",
        "    print(\"‚úÖ Repository cloned!\")\n",
        "\n",
        "!ls -la *.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üìä SETUP PROGRESS TRACKING - Install widgets for real-time training progress\n",
        "\n",
        "print(\"üì¶ Installing progress tracking widgets...\")\n",
        "\n",
        "# Install ipywidgets for progress bars and real-time updates\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "try:\n",
        "    import ipywidgets\n",
        "    print(\"‚úÖ ipywidgets already installed\")\n",
        "except ImportError:\n",
        "    print(\"Installing ipywidgets...\")\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"ipywidgets\"])\n",
        "    print(\"‚úÖ ipywidgets installed successfully!\")\n",
        "\n",
        "# Enable widgets extension\n",
        "try:\n",
        "    from IPython.display import display, HTML\n",
        "    print(\"‚úÖ IPython display ready\")\n",
        "    \n",
        "    # Test widget functionality\n",
        "    import ipywidgets as widgets\n",
        "    test_widget = widgets.FloatProgress(value=0, min=0, max=100, description='Test:')\n",
        "    print(\"‚úÖ Widget system working!\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è Widget setup issue: {e}\")\n",
        "    print(\"Progress will be shown as text output instead\")\n",
        "\n",
        "print(\"\\nüéØ Progress Tracking Ready!\")\n",
        "print(\"Your training will show:\")\n",
        "print(\"  üìä Real-time progress bar\")\n",
        "print(\"  ‚è±Ô∏è Elapsed time and remaining time estimates\")  \n",
        "print(\"  üìâ Current loss and best loss tracking\")\n",
        "print(\"  üî• Steps per second and ETA\")\n",
        "print(\"  üìà Live metrics dashboard\")\n",
        "\n",
        "print(\"\\n‚úÖ Ready to start training with visual progress tracking!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üì¶ Setup environment\n",
        "!pip install -q transformers peft accelerate bitsandbytes datasets\n",
        "\n",
        "import torch\n",
        "print(f\"üî• GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'None - Enable GPU!'}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üöÄ Train with your latest Cursor code!\n",
        "!python colab_training_pipeline.py --num_scenarios 100 --epochs 3 --max_length 512"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üß™ QUICK TEST - Verify your trained model works\n",
        "\n",
        "import os\n",
        "from technical_interview_bot import TechnicalInterviewBot\n",
        "\n",
        "print(\"üîç Checking trained model...\")\n",
        "\n",
        "# Check if model was saved successfully\n",
        "model_path = \"./technical_interview_model\"\n",
        "if os.path.exists(model_path):\n",
        "    print(f\"‚úÖ Model found at: {model_path}\")\n",
        "    \n",
        "    # Show model file sizes\n",
        "    print(\"\\nüìÅ Model files:\")\n",
        "    total_size = 0\n",
        "    for file in os.listdir(model_path):\n",
        "        file_path = os.path.join(model_path, file)\n",
        "        if os.path.isfile(file_path):\n",
        "            size_mb = os.path.getsize(file_path) / (1024 * 1024)\n",
        "            total_size += size_mb\n",
        "            print(f\"  - {file}: {size_mb:.1f} MB\")\n",
        "    print(f\"üìä Total model size: {total_size:.1f} MB\")\n",
        "    \n",
        "    print(\"\\nü§ñ Testing model loading...\")\n",
        "    \n",
        "    # Test loading the model\n",
        "    try:\n",
        "        bot = TechnicalInterviewBot(model_path)\n",
        "        \n",
        "        if bot.model is not None:\n",
        "            print(\"‚úÖ Model loaded successfully!\")\n",
        "            \n",
        "            # Quick test interview\n",
        "            print(\"\\nüî• Quick test - Starting sample interview...\")\n",
        "            response = bot.start_interview(\n",
        "                programming_language=\"python\",\n",
        "                experience_level=\"mid_level\", \n",
        "                candidate_name=\"Test User\"\n",
        "            )\n",
        "            \n",
        "            print(\"ü§ñ AI Response:\")\n",
        "            print(\"-\" * 60)\n",
        "            print(response[:300] + \"...\" if len(response) > 300 else response)\n",
        "            print(\"-\" * 60)\n",
        "            \n",
        "            print(\"\\nüéâ SUCCESS! Your CodeLlama model is working!\")\n",
        "            print(\"üåê Ready to launch web interface in the next cell!\")\n",
        "            \n",
        "        else:\n",
        "            print(\"‚ùå Model files found but failed to load\")\n",
        "            print(\"Check error messages above\")\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error testing model: {e}\")\n",
        "        print(\"Training may have failed or model files are corrupted\")\n",
        "        \n",
        "else:\n",
        "    print(f\"‚ùå Model not found at: {model_path}\")\n",
        "    print(\"Training may have failed or is still in progress\")\n",
        "    print(\"Make sure the training cell above completed successfully\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üåê LAUNCH WEB INTERFACE - Test your trained CodeLlama model!\n",
        "\n",
        "# Install Gradio for web interface\n",
        "%pip install gradio\n",
        "\n",
        "# Import required modules\n",
        "import sys\n",
        "import os\n",
        "sys.path.append('/content/interview-ai')\n",
        "\n",
        "print(\"üîç Checking for trained model...\")\n",
        "\n",
        "# Check if model exists\n",
        "model_path = './technical_interview_model'\n",
        "if os.path.exists(model_path):\n",
        "    print(\"‚úÖ Model found! Launching web interface...\")\n",
        "    \n",
        "    # List model files\n",
        "    print(\"\\nüìÅ Model files:\")\n",
        "    for file in os.listdir(model_path):\n",
        "        if os.path.isfile(os.path.join(model_path, file)):\n",
        "            size_mb = os.path.getsize(os.path.join(model_path, file)) / (1024 * 1024)\n",
        "            print(f\"  - {file}: {size_mb:.1f} MB\")\n",
        "    \n",
        "    # Import and launch web interface\n",
        "    from web_interface import launch_web_interface\n",
        "    \n",
        "    print(\"\\nüöÄ Starting Technical Interview AI Web Interface...\")\n",
        "    print(\"üí° This will create a public link accessible from any browser!\")\n",
        "    print(\"üîó Copy the gradio.live URL to access from your Mac/phone\")\n",
        "    \n",
        "    # Launch with public sharing enabled\n",
        "    launch_web_interface(share=True, port=7860)\n",
        "    \n",
        "else:\n",
        "    print(\"‚ùå Model not found at ./technical_interview_model\")\n",
        "    print(\"Make sure the training cell completed successfully before running this cell.\")\n",
        "    print(\"\\nüîß Troubleshooting:\")\n",
        "    print(\"1. Check if training finished without errors\")\n",
        "    print(\"2. Look for 'Training completed!' message above\")\n",
        "    print(\"3. Re-run the training cell if needed\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
